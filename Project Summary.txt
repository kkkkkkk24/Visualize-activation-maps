Project Summary: Age Detection with CNN & Activation Map Visualization
ğŸ” Objective:
To build a Convolutional Neural Network (CNN) model that predicts a person's age from facial images using the UTKFace dataset and visualizes activation maps to understand which facial regions influence model predictions.

ğŸ—ï¸ Methodology:
Dataset Used: UTKFace (images labeled with age, gender, and ethnicity)

Model Architecture: 3-layer CNN with ReLU activations, MaxPooling, and two fully connected layers.

Loss Function: Mean Squared Error (MSE) for age regression.

Optimizer: Adam

Activation Map Visualization: Captured outputs of intermediate convolutional layers to show which parts of the face the CNN focuses on.

ğŸ“ˆ Results:
Achieved reasonable training loss and age prediction performance (exact metrics can be filled post-evaluation).

Visualized activation maps clearly showing the network's attention on facial features like eyes, forehead, and mouth.

Demonstrated how CNN filters evolve in depth to extract abstract features.

ğŸ“Š Evaluation Metrics:
Accuracy (within Â±5 years): [Insert value]

Mean Absolute Error (MAE): [Insert value]

Confusion Matrix, Precision, and Recall for grouped age categories (0â€“20, 21â€“40, 41â€“60, 60+)

ğŸ“‚ Deliverables:
Jupyter Notebook for training and visualization

Saved model and weights (.pt)

Activation maps saved as .png files

requirements.txt for reproducibility

GitHub repository with organized code and documentation

ğŸ”— GitHub Repo:
[Insert your GitHub link here]

